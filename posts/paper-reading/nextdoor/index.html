<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>NextDoor | Hi-^_^</title>
<meta name=keywords content="GPU,GNN,GRAPH-SAMPLING">
<meta name=description content="Background 基本各种东西都可以用图来表示，也就促成了GNN的快速发展。然而很多图都有这样的特点，一些节点的度数很高然而大多数节点的度数很低。
训练时要用邻居更新当前节点，不能将整个图全部拿来训练，因此一般采用graph sampling+mini batch，比如，给$n$个节点，每个节点对邻居采样后在进行训练。
然而产生了新的问题，采样在整个训练过程中占了很多时间。
 因此，大家也会去想用GPU加速采样，但是naive的方法并不能很好的利用GPU。
&ldquo;Transit-Parallelism&rdquo; 作者首先对采样进行了抽象，采样从一节点开始，扩展出新的节点加入sample，再从新的节点扩展$\cdots$，每次遍历邻居扩展新节点的节点，作者把它叫做&#34;transit vertices&#34;
将采样分成两类：
 Individual Transit Sampling，这个是按节点来的，每个transit节点从邻居中采样一定数量的节点 Collective Transit Sampling，这个是按层来，每一层从所有transit节点的邻居中采样一定数量的节点    CUDA & GPU
一个CUDA程序被划分给很多blocks of threads完成并行，而GPU又由很多StreamingMultiprocessors (SMs)构成，每个block被放到SM上执行
 一个block的线程数是有限的，但是相同的大小block可以被组织成grid，于是kernel(a c++ function)就可以用grid里面所有的线程。 $$ thread \xrightarrow[]{array} block \xrightarrow[]{array} grid $$ 众所周知，内存层次结构，GPU当然也有：
 前面已经提到了block会在SM上执行，在物理实现时会用到SIMT(Single-Instruction, Multiple-Thread)。multiprocessor用warp(a group of 32 threads)来管理线程。
warp中的线程都从相同的起点开始，但是每个线程都有自己的pc，寄存器状态也可能不一样。而且一个warp的thread执行的指令还是相同的。
如果就是普通的没有控制流的代码，大家就一起执行。那遇到分支怎么办，每个线程可能有不同的路径。这时就会变成串行。warp去执行每个分支路径，不在路径上的thread就等着。这就可能会很影响并行，也就是Branch divergence。
 Sample-Parallelism，对于Individual Transit Sampling可以将每一对sample和transit分配$m_i$个线程，每个sample放到一个block里。对于Collective Transit Sampling，需要先把所有的邻居存到global memory里，再采样。
 在采样时，邻居多的节点计算的时间就会更久。如果同一个warp里面的两个thread被分给两个邻居数量不同的transit，就会有divergence。而且，图得存在gobal memory，shared memory利用不充分。
但是如果是按transit划分，局部性就会更好，按照工作量需求分配线程数量。是不是有点像倒排索引 :-)
 线程组中的线程，他们做的事情更相似，而且工作量也差不多。他们访问的邻居也是同一个transit的，能更好利用share memory。
Sampling Large Graphs NextDoor还可以去对超出GPU memory的图采样。方法有点像mini batch，把图分成不相交的子图，每次对一个子图和和其transit节点采样。">
<meta name=author content>
<link rel=canonical href=https://Anlarry.github.io/posts/paper-reading/nextdoor/>
<meta name=google-site-verification content="XYZabc">
<meta name=yandex-verification content="XYZabc">
<meta name=msvalidate.01 content="XYZabc">
<link crossorigin=anonymous href=/assets/css/stylesheet.min.b886e7a276371df860a94b50455814993fdf87cf36366827ac85854326387c68.css integrity="sha256-uIbnonY3HfhgqUtQRVgUmT/fh882NmgnrIWFQyY4fGg=" rel="preload stylesheet" as=style>
<link rel=preload href=/icon/ai512.png as=image>
<link ref=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/atom-one-dark.min.css>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js></script>
<script>hljs.highlightAll()</script>
<link href="https://fonts.googleapis.com/css?family=Source Code Pro" rel=stylesheet>
<link rel=icon href=https://Anlarry.github.io/icon/ai512.png>
<link rel=icon type=image/png sizes=16x16 href=https://Anlarry.github.io/icon/ai16.png>
<link rel=icon type=image/png sizes=32x32 href=https://Anlarry.github.io/icon/ai32.png>
<link rel=apple-touch-icon href=https://Anlarry.github.io/apple-touch-icon.png>
<link rel=mask-icon href=https://Anlarry.github.io/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.89.4">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-123-45','auto'),ga('send','pageview'))</script><meta property="og:title" content="NextDoor">
<meta property="og:description" content="Background 基本各种东西都可以用图来表示，也就促成了GNN的快速发展。然而很多图都有这样的特点，一些节点的度数很高然而大多数节点的度数很低。
训练时要用邻居更新当前节点，不能将整个图全部拿来训练，因此一般采用graph sampling+mini batch，比如，给$n$个节点，每个节点对邻居采样后在进行训练。
然而产生了新的问题，采样在整个训练过程中占了很多时间。
 因此，大家也会去想用GPU加速采样，但是naive的方法并不能很好的利用GPU。
&ldquo;Transit-Parallelism&rdquo; 作者首先对采样进行了抽象，采样从一节点开始，扩展出新的节点加入sample，再从新的节点扩展$\cdots$，每次遍历邻居扩展新节点的节点，作者把它叫做&#34;transit vertices&#34;
将采样分成两类：
 Individual Transit Sampling，这个是按节点来的，每个transit节点从邻居中采样一定数量的节点 Collective Transit Sampling，这个是按层来，每一层从所有transit节点的邻居中采样一定数量的节点    CUDA & GPU
一个CUDA程序被划分给很多blocks of threads完成并行，而GPU又由很多StreamingMultiprocessors (SMs)构成，每个block被放到SM上执行
 一个block的线程数是有限的，但是相同的大小block可以被组织成grid，于是kernel(a c++ function)就可以用grid里面所有的线程。 $$ thread \xrightarrow[]{array} block \xrightarrow[]{array} grid $$ 众所周知，内存层次结构，GPU当然也有：
 前面已经提到了block会在SM上执行，在物理实现时会用到SIMT(Single-Instruction, Multiple-Thread)。multiprocessor用warp(a group of 32 threads)来管理线程。
warp中的线程都从相同的起点开始，但是每个线程都有自己的pc，寄存器状态也可能不一样。而且一个warp的thread执行的指令还是相同的。
如果就是普通的没有控制流的代码，大家就一起执行。那遇到分支怎么办，每个线程可能有不同的路径。这时就会变成串行。warp去执行每个分支路径，不在路径上的thread就等着。这就可能会很影响并行，也就是Branch divergence。
 Sample-Parallelism，对于Individual Transit Sampling可以将每一对sample和transit分配$m_i$个线程，每个sample放到一个block里。对于Collective Transit Sampling，需要先把所有的邻居存到global memory里，再采样。
 在采样时，邻居多的节点计算的时间就会更久。如果同一个warp里面的两个thread被分给两个邻居数量不同的transit，就会有divergence。而且，图得存在gobal memory，shared memory利用不充分。
但是如果是按transit划分，局部性就会更好，按照工作量需求分配线程数量。是不是有点像倒排索引 :-)
 线程组中的线程，他们做的事情更相似，而且工作量也差不多。他们访问的邻居也是同一个transit的，能更好利用share memory。
Sampling Large Graphs NextDoor还可以去对超出GPU memory的图采样。方法有点像mini batch，把图分成不相交的子图，每次对一个子图和和其transit节点采样。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://Anlarry.github.io/posts/paper-reading/nextdoor/">
<meta property="og:image" content="https://Anlarry.github.io/image-20211114121110605.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2021-11-14T00:00:00+00:00">
<meta property="article:modified_time" content="2021-11-14T00:00:00+00:00"><meta property="og:site_name" content="Hi~, ^_^">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://Anlarry.github.io/image-20211114121110605.png">
<meta name=twitter:title content="NextDoor">
<meta name=twitter:description content="Background 基本各种东西都可以用图来表示，也就促成了GNN的快速发展。然而很多图都有这样的特点，一些节点的度数很高然而大多数节点的度数很低。
训练时要用邻居更新当前节点，不能将整个图全部拿来训练，因此一般采用graph sampling+mini batch，比如，给$n$个节点，每个节点对邻居采样后在进行训练。
然而产生了新的问题，采样在整个训练过程中占了很多时间。
 因此，大家也会去想用GPU加速采样，但是naive的方法并不能很好的利用GPU。
&ldquo;Transit-Parallelism&rdquo; 作者首先对采样进行了抽象，采样从一节点开始，扩展出新的节点加入sample，再从新的节点扩展$\cdots$，每次遍历邻居扩展新节点的节点，作者把它叫做&#34;transit vertices&#34;
将采样分成两类：
 Individual Transit Sampling，这个是按节点来的，每个transit节点从邻居中采样一定数量的节点 Collective Transit Sampling，这个是按层来，每一层从所有transit节点的邻居中采样一定数量的节点    CUDA & GPU
一个CUDA程序被划分给很多blocks of threads完成并行，而GPU又由很多StreamingMultiprocessors (SMs)构成，每个block被放到SM上执行
 一个block的线程数是有限的，但是相同的大小block可以被组织成grid，于是kernel(a c++ function)就可以用grid里面所有的线程。 $$ thread \xrightarrow[]{array} block \xrightarrow[]{array} grid $$ 众所周知，内存层次结构，GPU当然也有：
 前面已经提到了block会在SM上执行，在物理实现时会用到SIMT(Single-Instruction, Multiple-Thread)。multiprocessor用warp(a group of 32 threads)来管理线程。
warp中的线程都从相同的起点开始，但是每个线程都有自己的pc，寄存器状态也可能不一样。而且一个warp的thread执行的指令还是相同的。
如果就是普通的没有控制流的代码，大家就一起执行。那遇到分支怎么办，每个线程可能有不同的路径。这时就会变成串行。warp去执行每个分支路径，不在路径上的thread就等着。这就可能会很影响并行，也就是Branch divergence。
 Sample-Parallelism，对于Individual Transit Sampling可以将每一对sample和transit分配$m_i$个线程，每个sample放到一个block里。对于Collective Transit Sampling，需要先把所有的邻居存到global memory里，再采样。
 在采样时，邻居多的节点计算的时间就会更久。如果同一个warp里面的两个thread被分给两个邻居数量不同的transit，就会有divergence。而且，图得存在gobal memory，shared memory利用不充分。
但是如果是按transit划分，局部性就会更好，按照工作量需求分配线程数量。是不是有点像倒排索引 :-)
 线程组中的线程，他们做的事情更相似，而且工作量也差不多。他们访问的邻居也是同一个transit的，能更好利用share memory。
Sampling Large Graphs NextDoor还可以去对超出GPU memory的图采样。方法有点像mini batch，把图分成不相交的子图，每次对一个子图和和其transit节点采样。">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://Anlarry.github.io/posts/"},{"@type":"ListItem","position":2,"name":"NextDoor","item":"https://Anlarry.github.io/posts/paper-reading/nextdoor/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"NextDoor","name":"NextDoor","description":"Background 基本各种东西都可以用图来表示，也就促成了GNN的快速发展。然而很多图都有这样的特点，一些节点的度数很高然而大多数节点的度数很低。\n训练时要用邻居更新当前节点，不能将整个图全部拿来训练，因此一般采用graph sampling+mini batch，比如，给$n$个节点，每个节点对邻居采样后在进行训练。\n然而产生了新的问题，采样在整个训练过程中占了很多时间。\n 因此，大家也会去想用GPU加速采样，但是naive的方法并不能很好的利用GPU。\n\u0026ldquo;Transit-Parallelism\u0026rdquo; 作者首先对采样进行了抽象，采样从一节点开始，扩展出新的节点加入sample，再从新的节点扩展$\\cdots$，每次遍历邻居扩展新节点的节点，作者把它叫做\u0026quot;transit vertices\u0026quot;\n将采样分成两类：\n Individual Transit Sampling，这个是按节点来的，每个transit节点从邻居中采样一定数量的节点 Collective Transit Sampling，这个是按层来，每一层从所有transit节点的邻居中采样一定数量的节点    CUDA \u0026amp; GPU\n一个CUDA程序被划分给很多blocks of threads完成并行，而GPU又由很多StreamingMultiprocessors (SMs)构成，每个block被放到SM上执行\n 一个block的线程数是有限的，但是相同的大小block可以被组织成grid，于是kernel(a c++ function)就可以用grid里面所有的线程。 $$ thread \\xrightarrow[]{array} block \\xrightarrow[]{array} grid $$ 众所周知，内存层次结构，GPU当然也有：\n 前面已经提到了block会在SM上执行，在物理实现时会用到SIMT(Single-Instruction, Multiple-Thread)。multiprocessor用warp(a group of 32 threads)来管理线程。\nwarp中的线程都从相同的起点开始，但是每个线程都有自己的pc，寄存器状态也可能不一样。而且一个warp的thread执行的指令还是相同的。\n如果就是普通的没有控制流的代码，大家就一起执行。那遇到分支怎么办，每个线程可能有不同的路径。这时就会变成串行。warp去执行每个分支路径，不在路径上的thread就等着。这就可能会很影响并行，也就是Branch divergence。\n Sample-Parallelism，对于Individual Transit Sampling可以将每一对sample和transit分配$m_i$个线程，每个sample放到一个block里。对于Collective Transit Sampling，需要先把所有的邻居存到global memory里，再采样。\n 在采样时，邻居多的节点计算的时间就会更久。如果同一个warp里面的两个thread被分给两个邻居数量不同的transit，就会有divergence。而且，图得存在gobal memory，shared memory利用不充分。\n但是如果是按transit划分，局部性就会更好，按照工作量需求分配线程数量。是不是有点像倒排索引 :-)\n 线程组中的线程，他们做的事情更相似，而且工作量也差不多。他们访问的邻居也是同一个transit的，能更好利用share memory。\nSampling Large Graphs NextDoor还可以去对超出GPU memory的图采样。方法有点像mini batch，把图分成不相交的子图，每次对一个子图和和其transit节点采样。","keywords":["GPU","GNN","GRAPH-SAMPLING"],"articleBody":"Background 基本各种东西都可以用图来表示，也就促成了GNN的快速发展。然而很多图都有这样的特点，一些节点的度数很高然而大多数节点的度数很低。\n训练时要用邻居更新当前节点，不能将整个图全部拿来训练，因此一般采用graph sampling+mini batch，比如，给$n$个节点，每个节点对邻居采样后在进行训练。\n然而产生了新的问题，采样在整个训练过程中占了很多时间。\n 因此，大家也会去想用GPU加速采样，但是naive的方法并不能很好的利用GPU。\n“Transit-Parallelism” 作者首先对采样进行了抽象，采样从一节点开始，扩展出新的节点加入sample，再从新的节点扩展$\\cdots$，每次遍历邻居扩展新节点的节点，作者把它叫做\"transit vertices\"\n将采样分成两类：\n Individual Transit Sampling，这个是按节点来的，每个transit节点从邻居中采样一定数量的节点 Collective Transit Sampling，这个是按层来，每一层从所有transit节点的邻居中采样一定数量的节点    CUDA \u0026 GPU\n一个CUDA程序被划分给很多blocks of threads完成并行，而GPU又由很多StreamingMultiprocessors (SMs)构成，每个block被放到SM上执行\n 一个block的线程数是有限的，但是相同的大小block可以被组织成grid，于是kernel(a c++ function)就可以用grid里面所有的线程。 $$ thread \\xrightarrow[]{array} block \\xrightarrow[]{array} grid $$ 众所周知，内存层次结构，GPU当然也有：\n 前面已经提到了block会在SM上执行，在物理实现时会用到SIMT(Single-Instruction, Multiple-Thread)。multiprocessor用warp(a group of 32 threads)来管理线程。\nwarp中的线程都从相同的起点开始，但是每个线程都有自己的pc，寄存器状态也可能不一样。而且一个warp的thread执行的指令还是相同的。\n如果就是普通的没有控制流的代码，大家就一起执行。那遇到分支怎么办，每个线程可能有不同的路径。这时就会变成串行。warp去执行每个分支路径，不在路径上的thread就等着。这就可能会很影响并行，也就是Branch divergence。\n Sample-Parallelism，对于Individual Transit Sampling可以将每一对sample和transit分配$m_i$个线程，每个sample放到一个block里。对于Collective Transit Sampling，需要先把所有的邻居存到global memory里，再采样。\n 在采样时，邻居多的节点计算的时间就会更久。如果同一个warp里面的两个thread被分给两个邻居数量不同的transit，就会有divergence。而且，图得存在gobal memory，shared memory利用不充分。\n但是如果是按transit划分，局部性就会更好，按照工作量需求分配线程数量。是不是有点像倒排索引 :-)\n 线程组中的线程，他们做的事情更相似，而且工作量也差不多。他们访问的邻居也是同一个transit的，能更好利用share memory。\nSampling Large Graphs NextDoor还可以去对超出GPU memory的图采样。方法有点像mini batch，把图分成不相交的子图，每次对一个子图和和其transit节点采样。\nReference\n[1] Jangda A, Polisetty S, Guha A, et al. Accelerating graph sampling for graph machine learning using gpus[C]//Proceedings of the Sixteenth European Conference on Computer Systems. 2021: 311-326.\n[2] Ward I R, Joyner J, Lickfold C, et al. A Practical Guide to Graph Neural Networks[J]. arXiv preprint arXiv:2010.05234, 2020.\n[3] CUDA C++ Programming Guide\n","wordCount":"118","inLanguage":"en","image":"https://Anlarry.github.io/image-20211114121110605.png","datePublished":"2021-11-14T00:00:00Z","dateModified":"2021-11-14T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://Anlarry.github.io/posts/paper-reading/nextdoor/"},"publisher":{"@type":"Organization","name":"Hi-^_^","logo":{"@type":"ImageObject","url":"https://Anlarry.github.io/icon/ai512.png"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://Anlarry.github.io/ accesskey=h title="Jiali's Blog (Alt + H)">
<img src=/icon/ai512.png alt=logo aria-label=logo height=35>Jiali's Blog</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://Anlarry.github.io/archives/ title="Archives 📦">
<span>Archives 📦</span>
</a>
</li>
<li>
<a href=https://Anlarry.github.io/categories/ title="Categories 📂">
<span>Categories 📂</span>
</a>
</li>
<li>
<a href=https://Anlarry.github.io/tags/ title="Tags 🏷">
<span>Tags 🏷</span>
</a>
</li>
<li>
<a href=https://Anlarry.github.io/book_reading/ title="Book-Reading 📚">
<span>Book-Reading 📚</span>
</a>
</li>
<li>
<a href=https://Anlarry.github.io/links/ title="Links 🔗">
<span>Links 🔗</span>
</a>
</li>
<li>
<a href=https://Anlarry.github.io/search/ title="Search 🔍 (Alt + /)" accesskey=/>
<span>Search 🔍</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<link rel=stylesheet href=https://Anlarry.github.io/sass/single-main.css>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://Anlarry.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://Anlarry.github.io/posts/>Posts</a></div>
<h1 class=post-title>
NextDoor
</h1>
<div class=post-meta>📝 November 14, 2021&nbsp;·&nbsp;⌛ 1 min&nbsp;|&nbsp;
<a href=https://github.com/Anlarry/Anlarry.github.io/issues rel="noopener noreferrer" target=_blank>Suggest Changes</a>
</div>
</header> <div class=toc>
<details open>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><ul>
<li>
<a href=#background aria-label=Background>Background</a></li>
<li>
<a href=#transit-parallelism aria-label=&amp;ldquo;Transit-Parallelism&amp;rdquo;>&ldquo;Transit-Parallelism&rdquo;</a></li>
<li>
<a href=#sampling-large-graphs aria-label="Sampling Large Graphs">Sampling Large Graphs</a>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><h2 id=background>Background<a hidden class=anchor aria-hidden=true href=#background>#</a></h2>
<p>基本各种东西都可以用图来表示，也就促成了GNN的快速发展。然而很多图都有这样的特点，一些节点的度数很高然而大多数节点的度数很低。</p>
<p>训练时要用邻居更新当前节点，不能将整个图全部拿来训练，因此一般采用graph sampling+mini batch，比如，给$n$个节点，每个节点对邻居采样后在进行训练。</p>
<p>然而产生了新的问题，采样在整个训练过程中占了很多时间。</p>
<p>
<img src=./image-20211114114025150.png#center-small#center-medium alt>
</p>
<p>因此，大家也会去想用GPU加速采样，但是naive的方法并不能很好的利用GPU。</p>
<h2 id=transit-parallelism>&ldquo;Transit-Parallelism&rdquo;<a hidden class=anchor aria-hidden=true href=#transit-parallelism>#</a></h2>
<p>作者首先对采样进行了抽象，采样从一节点开始，扩展出新的节点加入sample，再从新的节点扩展$\cdots$，每次遍历邻居扩展新节点的节点，作者把它叫做"transit vertices"</p>
<p>将采样分成两类：</p>
<ol>
<li><strong>Individual Transit Sampling</strong>，这个是按节点来的，每个transit节点从邻居中采样一定数量的节点</li>
<li><strong>Collective Transit Sampling</strong>，这个是按层来，每一层从所有transit节点的邻居中采样一定数量的节点</li>
</ol>
<p>
<img src=image-20211114114804228.png#center alt=image-20211114114804228>
</p>
<blockquote>
<p><strong>CUDA & GPU</strong></p>
<p>一个CUDA程序被划分给很多blocks of threads完成并行，而GPU又由很多StreamingMultiprocessors (SMs)构成，每个block被放到SM上执行</p>
<p>
<img src=automatic-scalability.png#center alt="Automatic Scalability.">
</p>
<p>一个block的线程数是有限的，但是相同的大小block可以被组织成grid，于是kernel(a c++ function)就可以用grid里面所有的线程。
$$
thread \xrightarrow[]{array} block \xrightarrow[]{array} grid
$$
众所周知，内存层次结构，GPU当然也有：</p>
<p>
<img src=memory-hierarchy.png#center alt="Memory Hierarchy.">
</p>
<p>前面已经提到了block会在SM上执行，在物理实现时会用到SIMT(Single-Instruction, Multiple-Thread)。multiprocessor用warp(a group of 32 threads)来管理线程。</p>
<p>warp中的线程都从相同的起点开始，但是每个线程都有自己的pc，寄存器状态也可能不一样。而且一个warp的thread执行的指令还是相同的。</p>
<p>如果就是普通的没有控制流的代码，大家就一起执行。那遇到分支怎么办，每个线程可能有不同的路径。这时就会变成串行。warp去执行每个分支路径，不在路径上的thread就等着。这就可能会很影响并行，也就是Branch divergence。</p>
</blockquote>
<p><strong>Sample-Parallelism</strong>，对于Individual Transit Sampling可以将每一对sample和transit分配$m_i$个线程，每个sample放到一个block里。对于Collective Transit Sampling，需要先把所有的邻居存到global memory里，再采样。</p>
<p>
<img src=image-20211114120722353.png#center-medium alt=image-20211114120722353>
</p>
<p>在采样时，邻居多的节点计算的时间就会更久。如果同一个warp里面的两个thread被分给两个邻居数量不同的transit，就会有divergence。而且，图得存在gobal memory，shared memory利用不充分。</p>
<p>但是如果是按transit划分，局部性就会更好，按照工作量需求分配线程数量。是不是有点像倒排索引 :-)</p>
<p>
<img src=image-20211114121110605.png#center-medium alt=image-20211114121110605>
</p>
<p>线程组中的线程，他们做的事情更相似，而且工作量也差不多。他们访问的邻居也是同一个transit的，能更好利用share memory。</p>
<h2 id=sampling-large-graphs>Sampling Large Graphs<a hidden class=anchor aria-hidden=true href=#sampling-large-graphs>#</a></h2>
<p>NextDoor还可以去对超出GPU memory的图采样。方法有点像mini batch，把图分成不相交的子图，每次对一个子图和和其transit节点采样。</p>
<p><strong>Reference</strong></p>
<p>[1] Jangda A, Polisetty S, Guha A, et al. Accelerating graph sampling for graph machine learning using gpus[C]//Proceedings of the Sixteenth European Conference on Computer Systems. 2021: 311-326.</p>
<p>[2] Ward I R, Joyner J, Lickfold C, et al. A Practical Guide to Graph Neural Networks[J]. arXiv preprint arXiv:2010.05234, 2020.</p>
<p>[3] <a href=https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#abstract>CUDA C++ Programming Guide</a></p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://Anlarry.github.io/tags/gpu/>GPU</a></li>
<li><a href=https://Anlarry.github.io/tags/gnn/>GNN</a></li>
<li><a href=https://Anlarry.github.io/tags/graph-sampling/>GRAPH-SAMPLING</a></li>
</ul>
<nav class=paginav>
<a class=next href=https://Anlarry.github.io/posts/paper-reading/active-learning-for-ml-enhanced-database-systems/>
<span class=title>Next Page »</span>
<br>
<span>Active Learning for ML Enhanced Database Systems</span>
</a>
</nav>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2021 <a href=https://Anlarry.github.io/>Jiali Wang</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
<script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='📄';function d(){a.innerText='✔',setTimeout(()=>{a.innerText='📄'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script>
</body>
</html>